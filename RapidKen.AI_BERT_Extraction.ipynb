{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RapidKen.AI_BERT_Extraction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4BzySrE7uL7x","outputId":"688502a5-96a9-4e48-e050-16a66fd044a7","executionInfo":{"status":"ok","timestamp":1591343629719,"user_tz":-330,"elapsed":29083,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NRwxdM-ezHHU","outputId":"1e47fb99-e067-4d63-c6cf-e8d08e946c09","executionInfo":{"status":"ok","timestamp":1591343639988,"user_tz":-330,"elapsed":2828,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd /content/drive/MyDrive/BERT-keyphrase-extraction/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/BERT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NFnwHdon0IbF","outputId":"da1e86c2-061c-4cb9-8e13-41bdc377977d","executionInfo":{"status":"ok","timestamp":1591343717106,"user_tz":-330,"elapsed":12072,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import pytorch_pretrained_bert"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GsmC3vKh0QAR","outputId":"4a007f95-7f91-4a0a-b75b-74ce00618373","executionInfo":{"status":"ok","timestamp":1590948255367,"user_tz":-330,"elapsed":156662,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":679}},"source":["!python train.py --data_dir data/task1/ --bert_model_dir model/ --model_dir experiments/base_model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","device: cuda, n_gpu: 1, 16-bits training: False\n","Loading the datasets...\n","loading vocabulary file model/vocab.txt\n","loading archive file model/\n","Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 31090\n","}\n","\n","Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","Starting training for 2 epoch(s)\n","Epoch 1/2\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","100% 99/99 [00:11<00:00,  8.86it/s, loss=0.261]\n","- Train metrics: loss: 00.13; f1: 58.82\n","- Val metrics: loss: 00.21; f1: 47.31\n","val metrics : {'loss': 0.2097718596458435, 'f1': 47.310804378867196}\n","- Found new best F1\n","Epoch 2/2\n","100% 99/99 [00:12<00:00,  8.21it/s, loss=0.126]\n","- Train metrics: loss: 00.07; f1: 73.76\n","- Val metrics: loss: 00.21; f1: 52.60\n","val metrics : {'loss': 0.2087090915441513, 'f1': 52.59515570934256}\n","- Found new best F1\n","Best val f1: 52.60\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"StDDwSZT41Dx"},"source":["Importing required libraries\n"]},{"cell_type":"code","metadata":{"id":"2QvJnP5NQtsl","outputId":"8c0344f0-183b-4c06-bcd7-f3931d92e2e5","executionInfo":{"status":"ok","timestamp":1591110404201,"user_tz":-330,"elapsed":1424,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import random\n","import numpy as np\n","import os\n","import sys\n","\n","import torch\n","\n","from pytorch_pretrained_bert import BertTokenizer, BertForTokenClassification, BertConfig\n","\n","import utils"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1OuEzLRwQuG4"},"source":["class DataLoader(object):\n","    def __init__(self, data_dir, bert_model_dir, max_len, device, token_pad_idx=0):\n","        self.data_dir = data_dir\n","        self.max_len = max_len\n","        self.device = device\n","        self.seed = 23\n","        self.batch_size = 4\n","        self.token_pad_idx = 0\n","\n","        self.tokenizer = BertTokenizer.from_pretrained(bert_model_dir, do_lower_case=True)\n","\n","    def ret_tags(self):\n","        tags = self.load_tags()\n","        self.tag2idx = {tag: idx for idx, tag in enumerate(tags)}\n","        self.idx2tag = {idx: tag for idx, tag in enumerate(tags)}\n","        self.tag_pad_idx = self.tag2idx['O']\n","        return self.tag2idx, self.idx2tag\n","\n","    def load_tags(self):\n","        tags = []\n","        file_path = os.path.join(self.data_dir, 'task1' , 'tags.txt')\n","        with open(file_path, 'r', encoding=\"utf-8\") as file:\n","            for tag in file:\n","                tags.append(tag.strip())\n","        return tags\n","\n","    def load_sentences_tags(self, sentences_file, d):\n","        \"\"\"Loads sentences and tags from their corresponding files. \n","            Maps tokens and tags to their indices and stores them in the provided dict d.\n","        \"\"\"\n","        sentences = []\n","\n","        with open(sentences_file, 'r', encoding=\"utf-8\") as file:\n","            for line in file:\n","                # replace each token by its index\n","                tokens = line.split()\n","                sentences.append(self.tokenizer.convert_tokens_to_ids(tokens))\n","        \n","       # storing sentences and tags in dict d\n","        d['data'] = sentences\n","        d['size'] = len(sentences)\n","\n","    def load_data(self, data_type):\n","        \"\"\"Loads the data for each type in types from data_dir.\n","\n","        Args:\n","            data_type: (str) has one of 'train', 'val', 'test' depending on which data is required.\n","        Returns:\n","            data: (dict) contains the data with tags for each type in types.\n","        \"\"\"\n","        data = {}\n","        \n","        if data_type in ['train', 'val', 'test']:\n","            sentences_file = os.path.join(self.data_dir, 'h1_7.txt')\n","            self.load_sentences_tags(sentences_file, data)\n","        else:\n","            raise ValueError(\"data type not in ['train', 'val', 'test']\")\n","        return data\n","\n","    def data_iterator(self, data, shuffle=False):\n","        \"\"\"Returns a generator that yields batches data with tags.\n","\n","        Args:\n","            data: (dict) contains data which has keys 'data', 'tags' and 'size'\n","            shuffle: (bool) whether the data should be shuffled\n","            \n","        Yields:\n","            batch_data: (tensor) shape: (batch_size, max_len)\n","            batch_tags: (tensor) shape: (batch_size, max_len)\n","        \"\"\"\n","\n","        # make a list that decides the order in which we go over the data- this avoids explicit shuffling of data\n","        order = list(range(data['size']))\n","\n","        # one pass over data\n","        for i in range(data['size']//self.batch_size):\n","            # fetch sentences and tags\n","            sentences = [data['data'][idx] for idx in order[i*self.batch_size:(i+1)*self.batch_size]]\n","\n","            # batch length\n","            batch_len = len(sentences)\n","\n","            # compute length of longest sentence in batch\n","            batch_max_len = max([len(s) for s in sentences])\n","            max_len = min(batch_max_len, self.max_len)\n","\n","            # prepare a numpy array with the data, initialising the data with pad_idx\n","            batch_data = self.token_pad_idx * np.ones((batch_len, max_len))\n","\n","            # copy the data to the numpy array\n","            for j in range(batch_len):\n","                cur_len = len(sentences[j])\n","                if cur_len <= max_len:\n","                    batch_data[j][:cur_len] = sentences[j]\n","                else:\n","                    batch_data[j] = sentences[j][:max_len]\n","\n","            # since all data are indices, we convert them to torch LongTensors\n","            batch_data = torch.tensor(batch_data, dtype=torch.long)\n","\n","            # shift tensors to GPU if available\n","            batch_data = batch_data.to(self.device)\n","        \n","            yield batch_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OM3lvPSF5D40"},"source":["Model Initialization"]},{"cell_type":"code","metadata":{"id":"BlE6298OQu6Y","outputId":"4a3c1ea0-b29b-4c75-c81c-576b48728d36","executionInfo":{"status":"ok","timestamp":1591110414450,"user_tz":-330,"elapsed":9819,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["json_path = os.path.join('experiments/base_model', 'params.json')\n","data_dir = os.path.join('data/')\n","bert_model_dir = os.path.join('model/')\n","model_dir = os.path.join('experiments/base_model')\n","restore_file = os.path.join('best')\n","print(json_path)\n","\n","# Use GPUs if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Set the random seed for reproducible experiments\n","random.seed(23)\n","torch.manual_seed(23)\n","\n","# Initialize the DataLoader\n","params = utils.Params(json_path)\n","data_loader = DataLoader(data_dir, bert_model_dir, params.max_len,device, token_pad_idx=0)\n","tag2idx, idx2tag = data_loader.ret_tags()\n","print(\"- done.\")\n","\n","# Define the model\n","config_path = os.path.join(bert_model_dir, 'bert_config.json')\n","config = BertConfig.from_json_file(config_path)\n","model = BertForTokenClassification(config, num_labels=len(tag2idx))\n","\n","model.to(device)\n","# Reload weights from the saved file\n","chkpt = utils.load_checkpoint(os.path.join(model_dir, restore_file + '.pth.tar'), model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["experiments/base_model/params.json\n","- done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-O78UTvP5GOD"},"source":["Evaluation"]},{"cell_type":"code","metadata":{"id":"0Yc6RA3N00RF"},"source":["# Load data\n","test_data = data_loader.load_data('test')\n","# Specify the test set size\n","test_size = test_data['size']\n","\n","data_iterator = data_loader.data_iterator(test_data, shuffle=False)\n","\n","print(\"Starting evaluation...\")\n","model.eval()\n","pred_tags = []\n","eval_steps = test_size//4\n","\n","for _ in range(eval_steps):\n","    # fetch the next evaluation batch\n","    batch_data = next(data_iterator)\n","    batch_masks = batch_data.gt(0)\n","    batch_output = model(batch_data, token_type_ids=None, attention_mask=batch_masks)\n","\n","    batch_output = batch_output.detach().cpu().numpy()\n","    for indices in np.argmax(batch_output, axis=2):\n","      pred_tags.append([idx2tag.get(idx) for idx in indices])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bvfoR6xXTYp"},"source":["import numpy as np\n","np.array(pred_tags).dump(open('results_correct.npy', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vwl-MSXCnVzA","outputId":"fd147c2c-c778-403b-dabc-ad2c84d3d03f","executionInfo":{"status":"ok","timestamp":1591112347587,"user_tz":-330,"elapsed":1213,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(pred_tags), len(sentences)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2644, 2645)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"mpGD3s_CXUGd"},"source":["sentences_file = os.path.join(data_dir, 'h1_7.txt')\n","tokenizer = BertTokenizer.from_pretrained(bert_model_dir, do_lower_case=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OffDf1Q2XUC1"},"source":["sentences = []\n","with open(sentences_file, 'r', encoding=\"utf-8\") as file:\n","  for line in file:\n","    # replace each token by its index\n","    tokens = line.split()\n","    # print(tokens)\n","    sentences.append(tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0NTAXhG4XT-f","outputId":"8b318d77-ba62-436a-daa9-53a470d965cc","executionInfo":{"status":"ok","timestamp":1591112606994,"user_tz":-330,"elapsed":1056,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["print(sentences[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['Search', 'APIs'], [], ['Most', 'search', 'APIs', 'are', 'multi-index,', 'with', 'the', 'exception', 'of', 'the', 'Explain', 'API', 'endpoints.'], [], ['Routing'], [], ['When', 'executing', 'a', 'search,', 'Elasticsearch', 'will', 'pick', 'the', '\"best\"', 'copy', 'of', 'the', 'data', 'based', 'on', 'the', 'adaptive', 'replica', 'selection', 'formula.', 'Which', 'shards', 'will', 'be', 'searched', 'on', 'can', 'also', 'be', 'controlled', 'by', 'providing', 'the', 'routing', 'parameter.', 'For', 'example,', 'when', 'indexing', 'tweets,', 'the', 'routing', 'value', 'can', 'be', 'the', 'user', 'name:'], [], ['In', 'such', 'a', 'case,', 'if', 'we', 'want', 'to', 'search', 'only', 'on', 'the', 'tweets', 'for', 'a', 'specific', 'user,', 'we', 'can', 'specify', 'it', 'as', 'the', 'routing,', 'resulting', 'in', 'the', 'search', 'hitting', 'only', 'the', 'relevant', 'shard:'], []]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"54v42EGU5KdS"},"source":["Extraction of key phrases"]},{"cell_type":"code","metadata":{"id":"79cgiyHbXT4V"},"source":["extract = []\n","with open(sentences_file, 'r', encoding=\"utf-8\") as file:\n","  i=0\n","  for line in file:\n","    # replace each token by its index\n","    tokens = line.split()\n","    # print(tokens)\n","    # sentences.append(tokens)\n","    temp = []\n","    j=0\n","    for token in tokens:\n","      if pred_tags[i][j]=='I':\n","        temp.append(token)\n","        j+=1\n","    if len(temp)>0:\n","      extract.append(temp)\n","    i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CqGSMgjXTvh","outputId":"8ffaafae-605c-4352-9055-588f96128a14","executionInfo":{"status":"ok","timestamp":1591113026792,"user_tz":-330,"elapsed":1769,"user":{"displayName":"Pulkit Arora","photoUrl":"","userId":"12809684651071745012"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["extract[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['When',\n","  'executing',\n","  'a',\n","  'search,',\n","  'Elasticsearch',\n","  'will',\n","  'pick',\n","  'the',\n","  '\"best\"',\n","  'copy',\n","  'of',\n","  'the',\n","  'data',\n","  'based',\n","  'on',\n","  'the',\n","  'adaptive',\n","  'replica',\n","  'selection',\n","  'formula.'],\n"," ['In'],\n"," ['The',\n","  'routing',\n","  'parameter',\n","  'can',\n","  'be',\n","  'multi',\n","  'valued',\n","  'represented',\n","  'as',\n","  'a',\n","  'comma'],\n"," ['Response',\n","  'time',\n","  'of',\n","  'past',\n","  'requests',\n","  'between',\n","  'the',\n","  'coordinating',\n","  'node',\n","  'and',\n","  'the',\n","  'node',\n","  'containing',\n","  'the',\n","  'copy',\n","  'of',\n","  'the',\n","  'data'],\n"," ['Time', 'past', 'search', 'requests'],\n"," ['The',\n","  'queue',\n","  'size',\n","  'of',\n","  'the',\n","  'search',\n","  'threadpool',\n","  'on',\n","  'the',\n","  'node',\n","  'containing',\n","  'the',\n","  'data'],\n"," ['This',\n","  'can',\n","  'be',\n","  'turned',\n","  'off',\n","  'by',\n","  'changing',\n","  'the',\n","  'dynamic',\n","  'cluster',\n","  'setting',\n","  'cluster.routing.use_adaptive_replica_selection',\n","  'from',\n","  'true',\n","  'to',\n","  'false:'],\n"," ['If',\n","  'adaptive',\n","  'replica',\n","  'selection',\n","  'is',\n","  'turned',\n","  'off,',\n","  'searches',\n","  'are',\n","  'sent',\n","  'to',\n","  'the',\n","  'index/indices',\n","  'shards',\n","  'in',\n","  'a',\n","  'round',\n","  'robin',\n","  'fashion',\n","  'between',\n","  'all',\n","  'copies',\n","  'of',\n","  'the',\n","  'data',\n","  '(primaries',\n","  'and',\n","  'replicas).'],\n"," ['Individual',\n","  'searches',\n","  'can',\n","  'have',\n","  'a',\n","  'timeout',\n","  'as',\n","  'part',\n","  'of',\n","  'the',\n","  'Request'],\n"," ['Searches',\n","  'can',\n","  'be',\n","  'cancelled',\n","  'using',\n","  'standard',\n","  'task',\n","  'cancellation',\n","  'mechanism.']]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","source":[""],"metadata":{"id":"xtw7u-JxErFG"},"execution_count":null,"outputs":[]}]}